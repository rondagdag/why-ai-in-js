# TensorFlow.js Toxicity Demo

This project demonstrates how to use TensorFlow.js and the Toxicity model to classify sentences for toxic content.

## Getting Started

1. Open the `index.html` file in a web browser.
2. Open the browser's developer console to see the toxicity classification results.

## Files

- `index.html`: The main HTML file that includes the TensorFlow.js and Toxicity model scripts and runs the classification.

## How It Works

The `index.html` file loads the TensorFlow.js library and the Toxicity model. It then classifies a set of predefined sentences for toxic content and logs the results to the console.

## Dependencies

- [TensorFlow.js](https://cdn.jsdelivr.net/npm/@tensorflow/tfjs)
- [TensorFlow Toxicity Model](https://cdn.jsdelivr.net/npm/@tensorflow-models/toxicity)
- [Pre-trained TensorFlow.js models](https://github.com/tensorflow/tfjs-models)

## Example Sentences

The following sentences are classified for toxicity:

- "You are a tiny, little baby poop"
- "My favorite color is blue."
- "Shut up!"

## License

This project is licensed under the MIT License.